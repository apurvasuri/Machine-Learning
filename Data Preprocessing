#Importing Libraries
import numpy as np                        #contains mathematical tools
import matplotlib.pyplot as plt           #for plotting graphs and charts
import pandas as pd                       #for importing and managing dataset

#Importing Dataset
data=pd.read_csv('data.csv')
x=data.iloc[:,:-1].values                 #datatype: object(of data)
y=data.iloc[:,3].values                   #datatype: object(of data)

#Missing Data
from sklearn.preprocessing import Imputer #to take care of missing data
imp = Imputer(missing_values='NaN',strategy = 'mean',axis = 0) #made an object imp of Imputer() class
imp = imp.fit(x[:,1:3]) #to make imputer object fitted to data x
x[:,1:3] = imp.transform(x[:,1:3]) #replaces the missing data with mean of column

#Imputer(missing_values='NaN',strategy='mean',axis=0,verbose=0,copy=True)
#axis =0 we are taking mean among columns     
#axis =1 we are taking mean among rows
#Verbose controls verbosity of Imputer
"""
copy creates a copy of x, if false impution is done inplace. Even if copy is false a copy will be made for foll cases:
if x is not an array of floating values
if x is sparse and missing_values =0
if axis=0 and x is encoded as a CSR matrix
if axis=1 and x is encoded as a CSC matrix
"""
#x[:,1:3] = imp.fit_transform(x[:,1:3]) will also work the same way

#Categorical Data
from sklearn.preprocessing import LabelEncoder,OneHotEncoder
label_x = LabelEncoder()                                        # made an object label_x of class LabelEncoder()
x[:,0] = label_x.fit_transform(x[:,0])
onehot = OneHotEncoder(categorical_features = [0])              # made an object named onehot of class OneHotEncoder()
#categorical_features specifies what features are treated as categorical that is index of the categorical column i.e. 0
x = onehot.fit_transform(x).toarray()
label_y = LabelEncoder()
y = label_y.fit_transform(y)

#Splitting the data into train-test set
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state = 0)
# if test_size is not mentioned and train_size is also not mentioned it is set to 0.25
# random_state good choice is 42

#Feature Scaling
from sklearn.preprocessing import StandardScaler
sc_x = StandardScaler()
x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test) #we will not fit
# x_train and x_test are of same scale as we had fitted the sc_x object to x_train
# we will not apply feature scaling to y as it is a classification prob but if it were regression and range of values was big we
#would be applying feature scaling on y then
